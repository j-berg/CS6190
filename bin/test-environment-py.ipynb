{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ccdfeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from minepy import MINE\n",
    "import concurrent.futures\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb4839",
   "metadata": {},
   "source": [
    "### Load data and sample metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a3771e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\n",
    "    os.getcwd(),\n",
    "    \"..\",\n",
    "    \"data\",\n",
    "    \"S_cereviseae_compendia_recount_bio\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5b38e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\n",
    "        os.path.join(data_path, 'aggregated_metadata.json'), 'r') as jsonfile:\n",
    "    metadata_file = json.load(jsonfile)\n",
    "\n",
    "tables = {}\n",
    "for k, v in metadata_file['experiments'].items():\n",
    "    tables[v[\"accession_code\"]] = v\n",
    "    \n",
    "metadata = pd.DataFrame(tables).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f117ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded data with dimensions: (12428, 5370)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(os.path.join(data_path, \"SACCHAROMYCES_CEREVISIAE.tsv\"), sep=\"\\t\", header=0, index_col=0).T\n",
    "print(\"Loaded data with dimensions:\", str(data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf51e2d",
   "metadata": {},
   "source": [
    "### Load gene metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6fbf07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metadata for genes and extract genes with \"transporter\" annotation\n",
    "gene_mapper = pd.read_csv(os.path.join(\n",
    "    os.getcwd(),\n",
    "    \"..\",\n",
    "    \"data\",\n",
    "    \"yeast_orf_dict.csv\"\n",
    "), header=None, names=[\"id\", \"symbol\", \"name\", \"description\"])\n",
    "\n",
    "transporters = gene_mapper.loc[gene_mapper[\"description\"].str.contains(\"transporter\")]\n",
    "transporters_list = transporters[\"id\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9926df33",
   "metadata": {},
   "outputs": [],
   "source": [
    "gene_map = {}\n",
    "for i, r in gene_mapper.iterrows():\n",
    "    _id = str(r[\"id\"])\n",
    "    _name = str(r[\"symbol\"])\n",
    "    if _name != \"nan\":\n",
    "        gene_map[_id] = _name\n",
    "    else:\n",
    "        gene_map[_id] = _id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "378b7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, label_names, test_fraction=0.2, random_state=42):\n",
    "    \"\"\"Split input data into training and testing sets\n",
    "    \n",
    "    data        <pd.DataFrame> : Expects dataframe with genes as columns and samples as rows\n",
    "    label_names <array>        : List of name(s) that are labels\n",
    "    \"\"\"\n",
    "    \n",
    "    test = data.sample(\n",
    "        frac=test_fraction, \n",
    "        random_state=random_state,\n",
    "        axis=0)\n",
    "    train = data.loc[~data.index.isin(test.index)]\n",
    "    \n",
    "    X_test = test[test.columns.difference(label_names)]\n",
    "    y_test = test[label_names]\n",
    "    \n",
    "    X_train = train[train.columns.difference(label_names)]\n",
    "    y_train = train[label_names]\n",
    "    \n",
    "    feature_labels = [X_test.columns.tolist(), y_test.columns.tolist()]\n",
    "    \n",
    "    return np.array(X_train), np.array(X_test), np.array(y_train), np.array(y_test), feature_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1ab98a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_mic(args):\n",
    "    print(\"2\")\n",
    "    _id, arg_dict = args[0], args[1]\n",
    "    data = arg_dict[\"data\"]\n",
    "    print(\"Running \" + str(_id) + \"...\")\n",
    "    \n",
    "    X_train, X_test, y_train, y_test, feature_labels = split_data(data, [_id], test_fraction=0.3)\n",
    "    results = np.zeros(X_train.shape[1])\n",
    "\n",
    "    for i in range(X_train.shape[1]):\n",
    "        mine = MINE(alpha=0.6, c=15)\n",
    "        mine.compute_score(X_train[:, i], y_train[:, 0])\n",
    "        results[i] = mine.mic()\n",
    "\n",
    "    output = pd.DataFrame(results, index=feature_labels[0], columns=feature_labels[1])\n",
    "    output.to_csv(os.path.join(\"..\", \"mic_output\", _id + \".tsv\"), sep=\"\\t\")\n",
    "    print(_id + \" complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "97f9ea02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pools(\n",
    "    func,\n",
    "    arg_iter,\n",
    "    arg_dict):\n",
    "    \n",
    "    cores = arg_dict['workers']\n",
    "    pools = int(math.ceil(len(arg_iter) / arg_dict['workers']))\n",
    "    if pools < 1:\n",
    "        pools = 1\n",
    "    print(\"Processing {0} pool(s) on {1} core(s)...\".format(pools, cores))\n",
    "    \n",
    "    it_list = []\n",
    "    range_number = 0\n",
    "    for x in range(pools):\n",
    "        it_list.append([iter for iter in arg_iter[range_number:range_number + arg_dict['workers']]])\n",
    "        range_number += arg_dict['workers']\n",
    "    print(\"Divided data across {0} pool(s).\\n\".format(pools))\n",
    "    \n",
    "    batch_number = 1\n",
    "    for batch in it_list:\n",
    "        print(\"Starting: {0}...\".format(str([x[0] for x in batch])))\n",
    "        \n",
    "        with concurrent.futures.ProcessPoolExecutor(max_workers=arg_dict['workers']) as executor:\n",
    "            for gene in zip(batch, executor.map(func, batch)):\n",
    "                print(\"{0} has been processed.\".format(gene[0][0]))\n",
    "        \n",
    "        print('Processing of batch {0} of {1} complete...\\n'.format(batch_number, pools))\n",
    "        batch_number += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "20f6506a",
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_dict = {\n",
    "    \"workers\": cpu_count(),\n",
    "    \"data\": data\n",
    "}\n",
    "\n",
    "transporter_list = transporters[\"id\"].tolist()\n",
    "arg_iter = [[gene, arg_dict] for gene in transporter_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f12c154f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 27 pool(s) on 8 core(s)...\n",
      "Divided data across 27 pool(s).\n",
      "\n",
      "Starting: ['YAL067C', 'YAL022C', 'YJL219W', 'YJL214W', 'YJL212C', 'YJL198W', 'YJL193W', 'YJL165C']...\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBrokenProcessPool\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [109]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m----> 2\u001b[0m     \u001b[43mrun_pools\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_mic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [100]\u001b[0m, in \u001b[0;36mrun_pools\u001b[1;34m(func, arg_iter, arg_dict)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mstr\u001b[39m([x[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch])))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mProcessPoolExecutor(max_workers\u001b[38;5;241m=\u001b[39marg_dict[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mworkers\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[1;32m---> 24\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m gene \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch, executor\u001b[38;5;241m.\u001b[39mmap(func, batch)):\n\u001b[0;32m     25\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m has been processed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(gene[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing of batch \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m complete...\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(batch_number, pools))\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\concurrent\\futures\\process.py:484\u001b[0m, in \u001b[0;36m_chain_from_iterable_of_lists\u001b[1;34m(iterable)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_chain_from_iterable_of_lists\u001b[39m(iterable):\n\u001b[0;32m    479\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    480\u001b[0m \u001b[38;5;124;03m    Specialized implementation of itertools.chain.from_iterable.\u001b[39;00m\n\u001b[0;32m    481\u001b[0m \u001b[38;5;124;03m    Each item in *iterable* should be a list.  This function is\u001b[39;00m\n\u001b[0;32m    482\u001b[0m \u001b[38;5;124;03m    careful not to keep references to yielded objects.\u001b[39;00m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 484\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m    485\u001b[0m         element\u001b[38;5;241m.\u001b[39mreverse()\n\u001b[0;32m    486\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m element:\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\concurrent\\futures\\_base.py:619\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[1;34m()\u001b[0m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[0;32m    617\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[0;32m    618\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 619\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mpop()\u001b[38;5;241m.\u001b[39mresult(end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\concurrent\\futures\\_base.py:444\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[0;32m    443\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m--> 444\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    445\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[1;32m~\\miniconda3\\Lib\\concurrent\\futures\\_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m    388\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[0;32m    392\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mBrokenProcessPool\u001b[0m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run_pools(\n",
    "        run_mic,\n",
    "        arg_iter,\n",
    "        arg_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca14a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
